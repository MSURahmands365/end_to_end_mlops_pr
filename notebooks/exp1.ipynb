{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0345e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\msurahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\msurahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd \n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from revised_stopwords import get_revised_stopwords\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0c1840",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('IMDB_Dataset.csv')\n",
    "df=df.sample(5000)\n",
    "df.to_csv('data.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddbdf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df['sentiment'].isin(['positive','negative'])\n",
    "# df = df[x]\n",
    "# check if there two values or it contains any other too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4494db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msurahman\\AppData\\Local\\Temp\\ipykernel_15224\\2316282240.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment']=df[\"sentiment\"].replace({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=df[\"review\"]\n",
    "df['sentiment']=df[\"sentiment\"].replace({\n",
    "  'positive' or 'Positive':1,\n",
    "  'negative' or 'negative':0\n",
    "  \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9621148",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8daec4d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\msurahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "nltk.download('wordnet')\n",
    "def normalization(text):\n",
    "    # 1. Lowercase and URL removal (Best to do while it's still one string)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # 3. Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # 4. Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # 5. Tokenize, Stopword removal, and Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(get_revised_stopwords()) \n",
    "    words = text.split()\n",
    "    cleaned_words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    \n",
    "    return \" \".join(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b108f01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>pick year event basic instinct catherine trame...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7335</th>\n",
       "      <td>wonderful film never failed move colour convin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43334</th>\n",
       "      <td>disastermovie meaning word every character eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17703</th>\n",
       "      <td>would promising student film never seems know ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "3005   pick year event basic instinct catherine trame...          1\n",
       "7335   wonderful film never failed move colour convin...          1\n",
       "43334  disastermovie meaning word every character eve...          0\n",
       "17703  would promising student film never seems know ...          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[normalization(text) for text in x]\n",
    "preprocessed_df=pd.DataFrame({\"review\":x,\"sentiment\":y})\n",
    "preprocessed_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceaeeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv('preprocessed_data.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93e4a066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pick year event basic instinct catherine trame...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful film never failed move colour convin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>disastermovie meaning word every character eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>would promising student film never seems know ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tuned thing one night cable channel minute cre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>inherent problem staging merchant venice never...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>movie released biggest hit soon became blockbu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>meanspirited ugly nasty retroaction thriller b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>well goethe said really isnt point trying pas ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>show like watching someone training someday ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     pick year event basic instinct catherine trame...          1\n",
       "1     wonderful film never failed move colour convin...          1\n",
       "2     disastermovie meaning word every character eve...          0\n",
       "3     would promising student film never seems know ...          0\n",
       "4     tuned thing one night cable channel minute cre...          0\n",
       "...                                                 ...        ...\n",
       "4995  inherent problem staging merchant venice never...          1\n",
       "4996  movie released biggest hit soon became blockbu...          0\n",
       "4997  meanspirited ugly nasty retroaction thriller b...          1\n",
       "4998  well goethe said really isnt point trying pas ...          0\n",
       "4999  show like watching someone training someday ho...          0\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"preprocessed_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e794bb70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    2520\n",
       "1    2480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9c18d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f5928d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=CountVectorizer(max_features=1000)\n",
    "X=vectorizer.fit_transform(df['review'])\n",
    "y=df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e31ae43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 37 stored elements and shape (1, 1000)>\n",
      "  Coords\tValues\n",
      "  (0, 133)\t1\n",
      "  (0, 600)\t1\n",
      "  (0, 502)\t2\n",
      "  (0, 637)\t1\n",
      "  (0, 954)\t1\n",
      "  (0, 329)\t4\n",
      "  (0, 948)\t1\n",
      "  (0, 145)\t1\n",
      "  (0, 983)\t1\n",
      "  (0, 241)\t1\n",
      "  (0, 873)\t1\n",
      "  (0, 364)\t1\n",
      "  (0, 515)\t1\n",
      "  (0, 323)\t2\n",
      "  (0, 969)\t1\n",
      "  (0, 91)\t1\n",
      "  (0, 423)\t1\n",
      "  (0, 660)\t1\n",
      "  (0, 369)\t1\n",
      "  (0, 475)\t1\n",
      "  (0, 737)\t1\n",
      "  (0, 103)\t1\n",
      "  (0, 786)\t1\n",
      "  (0, 789)\t1\n",
      "  (0, 497)\t1\n",
      "  (0, 25)\t1\n",
      "  (0, 622)\t1\n",
      "  (0, 433)\t1\n",
      "  (0, 610)\t1\n",
      "  (0, 253)\t1\n",
      "  (0, 621)\t1\n",
      "  (0, 495)\t1\n",
      "  (0, 399)\t1\n",
      "  (0, 275)\t1\n",
      "  (0, 343)\t1\n",
      "  (0, 606)\t1\n",
      "  (0, 538)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3912a05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8f8aee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as MSURahmands365\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as MSURahmands365\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MSURahmands365/end_to_end_mlops_pr\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"MSURahmands365/end_to_end_mlops_pr\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MSURahmands365/end_to_end_mlops_pr initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository MSURahmands365/end_to_end_mlops_pr initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/b55325c816e94b0ab7eb1a5b0ff7ff1e', creation_time=1769431400143, experiment_id='0', last_update_time=1769431400143, lifecycle_stage='active', name='Logistic Regression Base Line', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "mlflow.set_tracking_uri('https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow')\n",
    "dagshub.init(repo_owner='MSURahmands365', repo_name='end_to_end_mlops_pr', mlflow=True)\n",
    "mlflow.set_experiment(\"Logistic Regression Base Line\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acad2d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 12:46:25,750 - INFO - Starting MLflow run...\n",
      "2026-01-27 12:46:26,615 - INFO - Logging preprocessing parameters...\n",
      "2026-01-27 12:46:27,733 - INFO - Initializing Logistic Regression model...\n",
      "2026-01-27 12:46:27,735 - INFO - Fitting the model...\n",
      "2026-01-27 12:46:27,917 - INFO - Model training complete.\n",
      "2026-01-27 12:46:27,918 - INFO - Logging model parameters...\n",
      "2026-01-27 12:46:28,364 - INFO - Making predictions...\n",
      "2026-01-27 12:46:28,366 - INFO - Calculating evaluation metrics...\n",
      "2026-01-27 12:46:28,384 - INFO - Logging evaluation metrics...\n",
      "2026-01-27 12:46:29,909 - INFO - Saving and logging the model...\n",
      "2026/01/27 12:46:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/27 12:46:42 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2026-01-27 12:46:46,279 - INFO - Model training and logging completed in 19.66 seconds.\n",
      "2026-01-27 12:46:46,281 - INFO - Accuracy: 0.805\n",
      "2026-01-27 12:46:46,282 - INFO - Precision: 0.7947154471544715\n",
      "2026-01-27 12:46:46,283 - INFO - Recall: 0.8061855670103093\n",
      "2026-01-27 12:46:46,283 - INFO - F1 Score: 0.8004094165813715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run magnificent-ray-187 at: https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow/#/experiments/0/runs/47fe4da654914dd7bf5c67fac23514f8\n",
      "üß™ View experiment at: https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 1000)\n",
    "        mlflow.log_param(\"test_size\", 0.20)\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "        # Log execution time\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        # mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # Print the results for verification\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end-to-end-mlops-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
