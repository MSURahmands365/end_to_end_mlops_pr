{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78f686fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0874007c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB_Dataset.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683cd732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]\n",
    "df\n",
    "# check if there two values or it contains any other too "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad83560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msurahman\\AppData\\Local\\Temp\\ipykernel_19652\\2428369636.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment']=df[\"sentiment\"].replace({\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x=df[\"review\"]\n",
    "df['sentiment']=df[\"sentiment\"].replace({\n",
    "  'positive' or 'Positive':1,\n",
    "  'negative' or 'negative':0\n",
    "  \n",
    "})\n",
    "df=df.sample(5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "688a93f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['review']\n",
    "y=df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58291a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "0    2501\n",
       "1    2499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05b467af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'those', 'has', 'when', 'yourselves', 'we', 'them', 'other', 'y', \"you've\", 'than', 'her', 'herself', \"she'll\", 'now', 'through', \"i'll\", \"they'll\", 'been', 'my', \"she'd\", 'she', 'his', 'an', 'some', \"it'll\", \"we'll\", 'whom', 'over', 'which', 'down', 'out', 'from', 'i', 'on', 'during', 'me', 'in', 've', 'what', \"they'd\", 'few', 'further', 'this', 'once', 'your', \"he's\", 'do', 'where', \"they've\", \"he'd\", \"i'm\", 'him', 'above', 'at', 're', 'yourself', 'with', 'be', 'that', 'until', 'was', 'did', \"we've\", \"it'd\", 'too', 'it', 'such', 'after', 'again', 'our', 'there', 'who', 'being', 'they', 'by', 'if', 'does', 'each', 'he', \"it's\", 'about', 'between', 'is', 'were', 'of', \"should've\", \"i've\", 'only', 'own', 'so', 'yours', 'up', \"we'd\", 'm', \"we're\", 'or', 'had', 'd', 'ours', 'themselves', 'll', 'a', 'both', \"he'll\", 'the', 'you', 'but', 'all', 'himself', 'itself', 'because', 'same', 'are', 'and', 'for', 'just', 'doing', 'below', 'these', 'o', 's', 'ourselves', 'their', 'theirs', 'will', 'have', 'into', 'should', 'why', 'hers', \"you're\", 'as', 'while', 'how', 'here', 'having', 'ma', 'before', \"you'll\", \"that'll\", 'then', \"they're\", 'its', 'under', \"you'd\", 'any', 'to', \"i'd\", 'myself', 't', 'can', 'am', \"she's\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\msurahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\msurahman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from revised_stopwords import get_revised_stopwords\n",
    "stopwords_list = get_revised_stopwords()\n",
    "nltk.download('punkt_tab')\n",
    "print(stopwords_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6b0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(get_revised_stopwords())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc18855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_text(text):\n",
    "  text=re.sub(r'<[^>]+>',' ',text)\n",
    "  stop_words=set(get_revised_stopwords())\n",
    "  tokens=word_tokenize(text)\n",
    "  filtered_tokens=[token for token in tokens if token.lower() not in stop_words]\n",
    "  stemmed_tokens=[PorterStemmer().stem(token) for token in filtered_tokens]\n",
    "  preprocessed_text= ' '.join(stemmed_tokens)\n",
    "  return preprocessed_text.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "710d88f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16034</th>\n",
       "      <td>saw film ( 's english titl `` 's sing ? '' ) 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24819</th>\n",
       "      <td>ultra cheezi soundtrack . vinni tri realli har...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44882</th>\n",
       "      <td>live mexico citi , suffer throug trailer everi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49156</th>\n",
       "      <td>watch movi scifi channel , conclud film made b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "16034  saw film ( 's english titl `` 's sing ? '' ) 1...          1\n",
       "24819  ultra cheezi soundtrack . vinni tri realli har...          0\n",
       "44882  live mexico citi , suffer throug trailer everi...          0\n",
       "49156  watch movi scifi channel , conclud film made b...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [preprocessed_text(text) for text in x]\n",
    "preprocessed_df=pd.DataFrame({\"review\":x,\"sentiment\":y})\n",
    "preprocessed_df.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f06ec397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7080f398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., 429, 908, 186],\n",
       "       [  0,   0,   0, ...,  68, 706,  82],\n",
       "       [  0,   0,   0, ..., 146, 420,  52],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,   1,  71,   8],\n",
       "       [  0,   0,   0, ..., 224, 971, 135],\n",
       "       [  0,   0,   0, ..., 172, 376, 320]], shape=(250, 500), dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts,test_texts,train_labels,test_labels=train_test_split(x,y,test_size=0.05,random_state=42)\n",
    "num_words=1000\n",
    "maxlen=500\n",
    "tokenizer=Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(x)\n",
    "\n",
    "\n",
    "train_sequences=tokenizer.texts_to_sequences(train_texts)\n",
    "test_sequences=tokenizer.texts_to_sequences(test_texts)\n",
    "# we have to give a fixed length of words to an algo that is why we are applying this\n",
    "train_data=pad_sequences(train_sequences,maxlen=maxlen)\n",
    "test_data=pad_sequences(test_sequences,maxlen=maxlen)\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fe98bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5000 entries, 16034 to 34895\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     5000 non-null   object\n",
      " 1   sentiment  5000 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65c6de31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"MSURahmands365/end_to_end_mlops_pr\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"MSURahmands365/end_to_end_mlops_pr\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository MSURahmands365/end_to_end_mlops_pr initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository MSURahmands365/end_to_end_mlops_pr initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/27 12:58:32 INFO mlflow.tracking.fluent: Experiment with name 'CNN & LSTM Base Line' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/df722788da374734bcc27f7e948e226a', creation_time=1769500712694, experiment_id='1', last_update_time=1769500712694, lifecycle_stage='active', name='CNN & LSTM Base Line', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "mlflow.set_tracking_uri('https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow')\n",
    "dagshub.init(repo_owner='MSURahmands365', repo_name='end_to_end_mlops_pr', mlflow=True)\n",
    "mlflow.set_experiment(\"CNN & LSTM Base Line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc653043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 15:28:13,211 - INFO - Starting MLflow run...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msurahman\\Documents\\projects\\End to End ML\\end_to_end_mlops_pr\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.6189 - loss: 0.6397 - val_accuracy: 0.7821 - val_loss: 0.4720\n",
      "Epoch 2/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 1s/step - accuracy: 0.8526 - loss: 0.3658 - val_accuracy: 0.8326 - val_loss: 0.3834\n",
      "Epoch 3/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9029 - loss: 0.2593 - val_accuracy: 0.8526 - val_loss: 0.3659\n",
      "Epoch 4/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 2s/step - accuracy: 0.9258 - loss: 0.2155 - val_accuracy: 0.8537 - val_loss: 0.3640\n",
      "Epoch 5/5\n",
      "\u001b[1m30/30\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.9397 - loss: 0.1817 - val_accuracy: 0.8495 - val_loss: 0.4007\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8640 - loss: 0.3587\n",
      "Test accuracy: 0.8640\n",
      "\u001b[1m8/8\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-27 15:32:02,453 - INFO - Logging evaluation metrics...\n",
      "2026-01-27 15:32:05,845 - INFO - Saving and logging the model...\n",
      "2026/01/27 15:32:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/27 15:32:09 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2026/01/27 15:32:30 WARNING mlflow.utils.environment: Failed to resolve installed pip version. ``pip`` will be added to conda.yaml environment spec without a version specifier.\n",
      "2026-01-27 15:32:39,590 - INFO - Model training and logging completed in 265.37 seconds.\n",
      "2026-01-27 15:32:39,592 - INFO - Accuracy: 0.864\n",
      "2026-01-27 15:32:39,594 - INFO - Precision: 0.8699186991869918\n",
      "2026-01-27 15:32:39,597 - INFO - Recall: 0.856\n",
      "2026-01-27 15:32:39,598 - INFO - F1 Score: 0.8629032258064516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run valuable-owl-67 at: https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow/#/experiments/1/runs/93636e7d42484765a3322d38a1481904\n",
      "ðŸ§ª View experiment at: https://dagshub.com/MSURahmands365/end_to_end_mlops_pr.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, LSTM, Dense, Dropout,Bidirectional\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "# 1.  Model Definition\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        model = Sequential([\n",
    "            Embedding(input_dim=num_words, output_dim=128, input_length=maxlen),\n",
    "\n",
    "            Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
    "            MaxPooling1D(pool_size=2),\n",
    "\n",
    "            Bidirectional(LSTM(64)),\n",
    "\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        # 2. Compile\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss='binary_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        # 3. Train\n",
    "        history = model.fit(train_data, train_labels,\n",
    "                            batch_size=128,\n",
    "                            epochs=5,\n",
    "                            validation_split=0.2)\n",
    "\n",
    "        # 4. Evaluate\n",
    "        loss, accuracy = model.evaluate(test_data, test_labels)\n",
    "        print(f'Test accuracy: {accuracy:.4f}')\n",
    "        y_predict=(model.predict(test_data)> 0.5).astype(\"int32\")\n",
    "        accuracy=accuracy_score(test_labels, y_predict)\n",
    "        precision=precision_score(test_labels, y_predict)\n",
    "        recall=recall_score(test_labels, y_predict)\n",
    "        f1=f1_score(test_labels, y_predict)\n",
    "        \n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_param(\"filter_size\", 128)\n",
    "        mlflow.log_param(\"lstm_units\", 64)\n",
    "        mlflow.log_param(\"epochs\", 5)\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        mlflow.tensorflow.log_model(model, artifact_path=\"model\")\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "        logging.info(f\"Accuracy: {accuracy}\")\n",
    "        logging.info(f\"Precision: {precision}\")\n",
    "        logging.info(f\"Recall: {recall}\")\n",
    "        logging.info(f\"F1 Score: {f1}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error Occured: {e}\", exc_info=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa582b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "end-to-end-mlops-pr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
